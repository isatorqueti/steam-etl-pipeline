# ğŸ“‰ Steam Data Pipeline 

Pipeline ETL *end-to-end* para ingestÃ£o, transformaÃ§Ã£o e anÃ¡lise histÃ³rica dos jogos mais populares da Steam usando **Python**, **Apache Airflow**, **Docker** e **PostgreSQL**.

---

## ğŸ“– VisÃ£o Geral

O objetivo deste projeto Ã© monitorar tendÃªncias de jogos em tempo real, criando um histÃ³rico ("sÃ©rie temporal") para analisar quais jogos estÃ£o ganhando ou perdendo popularidade.

- **ExtraÃ§Ã£o:** Coleta dados da API oficial da Steam.
- **TransformaÃ§Ã£o:** Limpeza, normalizaÃ§Ã£o e *timestamping* dos dados.
- **Carga:** Insere os dados processados em um banco PostgreSQL.
- **OrquestraÃ§Ã£o:** Todo o fluxo Ã© automatizado via **Apache Airflow**.

---

## ğŸ› ï¸ Stack TecnolÃ³gica

### Core
- **Python 3.14+** - Linguagem principal
- **Apache Airflow 3.1.7** - OrquestraÃ§Ã£o do pipeline
- **PostgreSQL 14** - Banco de dados relacional
- **Docker & Docker Compose** - ContainerizaÃ§Ã£o

### Bibliotecas Python
- **pandas** - ManipulaÃ§Ã£o e transformaÃ§Ã£o de dados
- **requests** - RequisiÃ§Ãµes HTTP para a API
- **SQLAlchemy** - ORM para interaÃ§Ã£o com o banco de dados
- **psycopg2** - Driver PostgreSQL
- **python-dotenv** - Gerenciamento de variÃ¡veis de ambiente

### Outras Ferramentas
- **Redis** - Message broker para Celery
- **Jupyter Notebook** - AnÃ¡lise exploratÃ³ria de dados
- **UV** - Gerenciador de pacotes Python rÃ¡pido

---

## ğŸ—‚ï¸ Estrutura do Projeto

```text
steam-etl-pipeline/
â”œâ”€â”€ config/                # ConfiguraÃ§Ãµes do pipeline (ignorado pelo git)
â”‚   â””â”€â”€ .env               
â”œâ”€â”€ dags/                  # DiretÃ³rio mapeado para o Airflow
â”‚   â”œâ”€â”€ steam_dag.py       
â”œâ”€â”€ data/                  # Dados extraÃ­dos (ignorado pelo git)
â”œâ”€â”€ logs/                  # Logs do Airflow (ignorado pelo git)
â”œâ”€â”€ plugins/               # Plugins do Airflow (ignorado pelo git)
â”œâ”€â”€ notebooks/             # Notebook de anÃ¡lise e exploraÃ§Ã£o
â”œâ”€â”€ src/                   # CÃ³digo fonte do ETL
â”‚   â”œâ”€â”€ extract_data.py
â”‚   â”œâ”€â”€ transform_data.py
â”‚   â””â”€â”€ load_data.py
â”œâ”€â”€ .env                   
â”œâ”€â”€ docker-compose.yaml    # OrquestraÃ§Ã£o dos containers
â”œâ”€â”€ main.py                # Usado para testar o pipeline
â””â”€â”€ README.md
```

## ğŸ§© Principais Arquivos

- `dags/steam_dag.py`: DAG principal do Airflow
- `src/extract_data.py`: FunÃ§Ã£o de extraÃ§Ã£o da API
- `src/transform_data.py`: FunÃ§Ãµes de transformaÃ§Ã£o
- `src/load_data.py`: FunÃ§Ã£o de carga no PostgreSQL
- `main.py`: ExecuÃ§Ã£o manual do pipeline

---

## ğŸ” Detalhamento das Etapas

### ğŸ“¥ **ETAPA 1: EXTRACT**

**Arquivo:** [`src/extract_data.py`](src/extract_data.py)

**O que faz:**
1. Realiza requisiÃ§Ãµes GET para os endpoints da Steam Web API:
- ISteamChartsService/GetGamesByConcurrentPlayers (Ranking)
- IStoreService/GetAppList (Nomes dos Jogos)
2. Salva os dados brutos em formato JSON na pasta dags/data/.

**Dados coletados:**
- Rank atual
- ID do Jogo (AppID)
- NÃºmero de jogadores simultÃ¢neos
- Pico de jogadores nas Ãºltimas 24h

---

### ğŸ”„ **ETAPA 2: TRANSFORM**

**Arquivo:** [`src/transform_data.py`](src/transform_data.py)

**O que faz:**

#### 2.1 **CriaÃ§Ã£o dos DataFrames**
- LÃª os arquivos JSON
- Converte para DataFrame Pandas

#### 2.2 **Merge e Limpeza**
- Cruza as informaÃ§Ãµes do Ranking com a lista de Apps (merge via appid).
- Remove colunas desnecessÃ¡rias para a anÃ¡lise (ex: last_modified, price_change_number).
- Renomeia as colunas para padronizaÃ§Ã£o de nomes claros.

#### 2.3 **Tratamento de dados Nulos**
- Para 'game_title' null, utilizamos "Desconhecido".

#### 2.4 **CriaÃ§Ã£o de SÃ©rie Temporal**
- Adiciona a coluna 'extracted_at' com data/hora atual.

**Resultado:** DataFrame limpo, estruturado e pronto para anÃ¡lise

---

### ğŸ’¾ **ETAPA 3: LOAD**

**Arquivo:** [`src/load_data.py`](src/load_data.py)

**O que faz:**

#### 3.1 **ConexÃ£o com o banco de dados**
```python
engine = create_engine(
    f"postgresql+psycopg2://{user}:{password}@{host}:5432/{database}"
)
```

#### 3.2 **InserÃ§Ã£o dos dados**
```python
df.to_sql(
        name=table_name,
        con=engine,
        if_exists='append',
        index=False
    )
```

#### 3.3 **ValidaÃ§Ã£o**
- Faz um `SELECT COUNT(*)` para verificar total de registros
- Loga o resultado para auditoria


---

## ğŸ³ Infraestrutura e OrquestraÃ§Ã£o

### 1. Docker (ContainerizaÃ§Ã£o)
O projeto Ã© totalmente isolado utilizando containers Docker, garantindo que o pipeline funcione em qualquer mÃ¡quina sem conflitos de dependÃªncia.
- **ServiÃ§os:** O `docker-compose.yaml` orquestra mÃºltiplos serviÃ§os simultaneamente: Airflow (Webserver, Scheduler, Triggerer) e o banco de dados PostgreSQL.
- **PersistÃªncia de Dados:** Utilizamos volumes Docker para garantir que os dados do banco (`postgres-db-volume`) nÃ£o sejam perdidos ao reiniciar os containers.
- **Networking:** ConfiguraÃ§Ã£o de rede interna para permitir a comunicaÃ§Ã£o direta entre o Airflow e o Postgres.

### 2. Apache Airflow (OrquestraÃ§Ã£o)
O gerenciamento do fluxo de dados Ã© feito pelo Airflow.
- **TaskFlow API:** O cÃ³digo utiliza a abordagem moderna do Airflow 2.0+ (`@dag`, `@task`), tornando o cÃ³digo mais limpo e legÃ­vel.
- **DependÃªncias:** O fluxo Ã© linear (`extract` >> `transform` >> `load`), garantindo que uma etapa sÃ³ inicie se a anterior for concluÃ­da com sucesso.
- **IdempotÃªncia:** O pipeline foi desenhado para rodar mÃºltiplas vezes sem quebrar, apenas adicionando novos registros histÃ³ricos.

---

## âš™ï¸ Como Executar

### 1. PrÃ©-requisitos
- **Docker** e **Docker Compose** instalados na mÃ¡quina.
- Uma **API Key da Steam** (vocÃª pode obter gratuitamente [aqui](https://steamcommunity.com/dev/apikey)).

### 2. ConfiguraÃ§Ã£o do Ambiente

Crie um arquivo chamado `.env` dentro da pasta `config/` e preencha com suas credenciais:

```env
# ConfiguraÃ§Ãµes da API Steam
API_KEY=sua_chave_aqui

# ConfiguraÃ§Ãµes do Banco de Dados (Postgres)
# Nota: 'host.docker.internal' permite que o container acesse o host/outros serviÃ§os
DB_HOST=host.docker.internal
DB_NAME=steam_data
DB_USER=airflow
DB_PASS=airflow
DB_PORT=5432
```

---

## ğŸ“Œ ReferÃªncia

Este projeto foi inspirado em um conteÃºdo do canal [**vbluuiza**](https://youtu.be/I8qPqbXQBDU?si=lbhwEALHXY7vN4NN) e adaptado para fins de aprendizado.

---

## ğŸ‘©â€ğŸ’» Desenvolvido por

- **Nome:** Isadora Torqueti
- **GitHub:** https://github.com/isatorqueti
- **Linkedin:** https://www.linkedin.com/in/isadoratorqueti/